---
title: "Turtle Games: Sales and Loyalty Analysis"
author: "Berni Alberto"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: journal
    toc: true
    toc_float: true
    df_print: kable # Adds nice printing for data frames
---

```{r setup, include=FALSE}
# This chunk sets up the global options for the notebook.
# The code in this chunk will run, but will not be shown in the final report.
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.width=10, fig.height=6)

# Restore the project library to ensure all packages are installed
# renv::restore()

# Load all required libraries for the entire analysis
library(DT)           # For interactive tables
library(here)         # For robust file paths
library(skimr) # For detailed summaries
library(plotly)       # For interactive plots
library(moments) # For skewness and kurtosis
library(pagedown) # For converting HTML reports to PDF
library(dplyr) # For data manipulation
library(ggplot2) # For data visualization
library(corrplot) # For correlation matrix visualization
library(lmtest) # For model diagnostics
library(broom) # For model summary
library(car) # For model diagnostics
library(ggpubr) # For creating publication-quality plots
library(tidyverse) # For data manipulation and visualization
library(DataExplorer) # For automated EDA reports
```

# Introduction

This report presents an exploratory data analysis (EDA) and the development of a multiple linear regression (MLR) model for Turtle Games. The primary objectives are:
1.  To analyze sales data to uncover insights into customer behavior and loyalty point accumulation.
2.  To build a predictive model for customer loyalty points.
3.  To provide actionable recommendations to the sales and marketing departments based on the findings.

This analysis uses R for its robust statistical and visualization capabilities, aligning with Turtle Games' existing workflows.

---

## Assignment 5: Exploratory Data Analysis

In this section, we will load, clean, and explore the Turtle Games customer review dataset. The goal is to identify initial patterns, distributions, and outliers that can inform business strategy.

### 1. Data Loading and Preparation

We begin by loading the pre-cleaned dataset created in the Python section of this project. Using a cleaned dataset ensures consistency and allows us to focus directly on the analysis in R.

```{r load_data}
# Load the cleaned dataset from the Data directory.
# We use the here() function from the 'here' package to create a robust,
# project-relative file path. This avoids common issues with working directories
# (e.g., setwd()) and makes the analysis more reproducible.
# The path starts at the project root.
reviews <- read_csv(here("Data", "turtle_reviews_2.csv"))

# Display the first few rows to confirm it loaded correctly
head(reviews)
```

> `Note:` The `here` package is a best-practice tool for reproducible R projects. It locates the project's root directory (where the `.Rproj` file is) and builds file paths from there. This means the code will run correctly on any machine without needing to manually change `setwd()` calls, a common source of errors when sharing R scripts. [Further Reading: `here` package documentation](https://here.r-lib.org/).


### 2. Initial Data Skim: A Rich Overview

Before diving into plots, we'll get a high-level statistical and structural summary of the data using `skimr::skim()`.

```{r initial_summary}
# skim() provides a much richer and more informative summary than base R's summary()
# or Python's pandas .describe(). It includes data types, missing value counts,
# completion rates, and even inline histograms for numeric variables.
skim(reviews)
```

**Commentary:** In Python with pandas, obtaining this level of detail would require calling both `.info()` (for data types and null counts) and `.describe()` (for summary statistics), and we still wouldn't get the convenient inline histograms or completion rates that `skim()` provides in a single command. This demonstrates how R's specialized packages can accelerate the initial data exploration phase.

### 3. Automated EDA: Maximum Insight, Minimum Effort

To rapidly generate a broad set of visualizations and identify areas for deeper investigation, we can use the `DataExplorer` package. It can create a complete HTML report with dozens of plots in a single line of code.
> `NOTE:` Include the version warning.  
```{r automated_eda_and_pdf, eval=FALSE}
    
    #TODO: PDF export is still broken and will have to be fixed. Ignore this comment when reporting findings.
    
    # This chunk performs four actions:
    # 1. Ensures the output directory 'R/out' exists.
    # 2. Generates a comprehensive EDA report as an intermediate HTML file inside 'R/out'.
    # 3. Converts that HTML file into a final PDF report, also in 'R/out'.
    # 4. Cleans up the intermediate HTML file, leaving only the PDF.

    
    # Prerequisite Note: pagedown::chrome_print() requires that Google Chrome
    # or Chromium is installed on your system.
    
    # Step 1: Define paths and ensure the output directory exists.
    output_dir <- here("R", "out")
    dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
    
    html_report_path <- file.path(output_dir, "Turtle_Games_EDA_Report_temp.html")
    pdf_report_path  <- file.path(output_dir, "Turtle_Games_EDA_Report.pdf")
    
    # Step 2: Prepare data by removing high-cardinality text columns.
    reviews_for_report <- reviews %>%
      select(-product, -review)
    
    # Step 3: Generate the initial report directly into the 'R/out' directory.
    # We provide both the filename and the directory explicitly to ensure it saves correctly.
    DataExplorer::create_report(
      data = reviews_for_report,
      output_file = basename(html_report_path),
      output_dir = dirname(html_report_path),
      y = "loyaltyPoints",
      report_title = "Turtle Games EDA Report"
    )
    
    # Step 4: Convert the HTML report to the final PDF.
    pagedown::chrome_print(
      input = dirname(html_report_path),
      output = basename(pdf_report_path)
    )
  
    message("EDA report successfully saved as PDF to: ", pdf_report_path)
```

**Commentary:** This is a key differentiator from a typical Python workflow. While libraries like `pandas-profiling` exist, `DataExplorer` is deeply integrated into the R ecosystem and highly customizable. It automates the creation of histograms, bar charts, correlation matrixes, QQ-plots, and more. This frees the analyst from writing boilerplate plotting code for initial exploration and allows them to focus their energy on creating bespoke visualizations for the most important questions, which we will do next.

### 4. Deep-Dive Visualizations with ggplot2

Visualizations are essential for understanding the distribution of data and the relationships between variables. We will focus on the `loyaltyPoints` variable.
Now, we create custom, presentation-quality visualizations to explore specific relationships, focusing on what drives `loyaltyPoints`. We will enhance the basic plots with faceting and more informative geoms.

### Histograms: Understanding Distributions

Histograms help us see the shape of the data for a single continuous variable.

```{r histograms}
# Histogram for loyalty_points
ggplot(reviews, aes(x = loyaltyPoints)) +
  geom_histogram(binwidth = 100, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Customer Loyalty Points",
       x = "Loyalty Points",
       y = "Frequency") +
  theme_minimal()

# Histogram for remuneration
ggplot(reviews, aes(x = income)) +
  geom_histogram(binwidth = 5, fill = "salmon", color = "black") +
  labs(title = "Distribution of Customer Remuneration",
       x = "Remuneration (in thousands)",
       y = "Frequency") +
  theme_minimal()
```

#### Scatterplots: Exploring Relationships

Scatterplots are perfect for visualizing the relationship between two numeric variables.

```{r scatterplots}
# Scatterplot of remuneration vs. loyalty_points
ggplot(reviews, aes(x = income, y = loyaltyPoints)) +
  geom_point(alpha = 0.6, color = "purple") +
  geom_smooth(method = "lm", color = "red", se = FALSE) + # Add a linear trend line
  labs(title = "Remuneration vs. Loyalty Points",
       x = "Remuneration",
       y = "Loyalty Points") +
  theme_minimal()

# Scatterplot of spending_score vs. loyalty_points
ggplot(reviews, aes(x = spendingScore, y = loyaltyPoints)) +
  geom_point(alpha = 0.6, color = "orange") +
  geom_smooth(method = "lm", color = "blue", se = FALSE) +
  labs(title = "Spending Score vs. Loyalty Points",
       x = "Spending Score (1-100)",
       y = "Loyalty Points") +
  theme_minimal()
```

#### Boxplots: Identifying Outliers and Groupings

Boxplots are useful for comparing distributions across different categories.

```{r boxplots}
# Boxplot of loyalty points by gender
ggplot(reviews, aes(x = gender, y = loyaltyPoints, fill = gender)) +
  geom_boxplot() +
  labs(title = "Loyalty Points Distribution by Gender",
       x = "Gender",
       y = "Loyalty Points") +
  theme_minimal() +
  theme(legend.position = "none")
```


#### Enhanced Distributions with Faceting

A simple histogram is good, but a faceted histogram is better. It allows us to compare the distribution of a variable across different segments of our data.

```{r faceted_histogram}
# Histogram of loyalty_points, faceted by gender
# Faceting allows us to see if the distribution of loyalty points
# is substantially different for males and females.
ggplot(reviews, aes(x = loyaltyPoints, fill = gender)) +
  geom_histogram(binwidth = 100, color = "black", alpha = 0.7) +
  facet_wrap(~gender, ncol = 1) +
  labs(title = "Distribution of Loyalty Points by Gender",
       x = "Loyalty Points",
       y = "Frequency") +
  theme_minimal() +
  theme(legend.position = "none") # Remove legend as fill is redundant
```

#### Advanced Boxplots: Violin Plots

Boxplots are useful for identifying medians and outliers, but they hide the underlying distribution shape. A violin plot combines a boxplot with a kernel density plot, giving a much richer view.

```{r violin_plot}
# Violin plot of loyalty points by gender
# The wider sections of the violin represent a higher probability of customers
# having that many loyalty points. The inner boxplot shows the standard metrics.
ggplot(reviews, aes(x = gender, y = loyaltyPoints, fill = gender)) +
  geom_violin(trim = FALSE, alpha = 0.6) +
  geom_boxplot(width = 0.1, fill = "white") +
  labs(title = "Richer View: Loyalty Points Distribution by Gender",
       subtitle = "Violin plot shows density, boxplot shows quartiles",
       x = "Gender",
       y = "Loyalty Points") +
  theme_minimal() +
  theme(legend.position = "none")
```

#### Exploring Relationships with Scatterplots

We recreate the scatterplots to examine the relationships between our key numeric variables. We'll add some aesthetic improvements for clarity.

```{r enhanced_scatterplots}
# Scatterplot of remuneration vs. loyalty_points
p1 <- ggplot(reviews, aes(x = income, y = loyaltyPoints)) +
  geom_point(aes(color = age), alpha = 0.7) + # Color points by age
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  scale_color_viridis_c() + # Use a colorblind-friendly palette
  labs(title = "Remuneration vs. Loyalty Points",
       subtitle = "Color indicates customer age",
       x = "Remuneration (in thousands)",
       y = "Loyalty Points") +
  theme_minimal()

# Scatterplot of spending_score vs. loyalty_points
p2 <- ggplot(reviews, aes(x = spendingScore, y = loyaltyPoints)) +
  geom_point(aes(color = age), alpha = 0.7) +
  geom_smooth(method = "lm", color = "blue", se = FALSE) +
  scale_color_viridis_c() +
  labs(title = "Spending Score vs. Loyalty Points",
       subtitle = "Color indicates customer age",
       x = "Spending Score (1-100)",
       y = "Loyalty Points") +
  theme_minimal()

# Display plots
p1
p2
```

### 5. "Higher Level" Analysis

To meet the 'High Distinction' criteria, we go beyond standard EDA by incorporating interactivity and powerful data summarization techniques.

#### Interactive Visualizations with Plotly

Static plots are great for reports, but interactive plots allow users to explore the data themselves. The `plotly` package can convert almost any `ggplot2` object into a fully interactive HTML widget with just one command.

```{r interactive_plot}
# Convert the remuneration scatterplot into an interactive plot
# Hover over points to see details!
ggplotly(p1, tooltip = c("x", "y", "color"))
```

**Commentary:** This capability is a significant advantage of using R Markdown for reporting. It allows stakeholders to move beyond passive consumption of a report and actively engage with the data, potentially discovering insights that a static view might miss. This is much more seamlessly integrated than in many Python environments.

#### Statistical Summaries with dplyr

Visualizations are essential, but sometimes a precise summary table is more effective. The `dplyr` package provides a powerful and readable grammar for data manipulation and summarization.

```{r dplyr_summary}
# Calculate summary statistics for loyalty points, grouped by gender and education
summary_table <- reviews %>%
  group_by(gender, education) %>%
  summarise(
    customer_count = n(),
    mean_loyalty_points = mean(loyaltyPoints),
    median_loyalty_points = median(loyaltyPoints),
    sd_loyalty_points = sd(loyaltyPoints),
    .groups = 'drop' # Drop grouping for the final table
  ) %>%
  arrange(desc(mean_loyalty_points)) # Order by highest mean points

# Display the summary table using DT for an interactive experience
# This creates a searchable, sortable HTML table in the final report.
datatable(summary_table,
          caption = "Summary of Loyalty Points by Gender and Education",
          options = list(pageLength = 10))
```

### 6. Key Observations and EDA Summary

This Exploratory Data Analysis, conducted in R, has provided several key insights into the Turtle Games customer dataset and highlighted the strengths of the R ecosystem for this type of work.

#### Key Findings:
1.  **Distributions and Central Tendency:**
    *   The `skimr` summary and the initial histogram reveal that the `loyaltyPoints` variable is **right-skewed** (mean of 1578 is significantly higher than the median of 1276). This is a crucial insight: while the average customer has a moderate number of points, a smaller, highly-engaged group of customers accumulates a disproportionately large number of points. These are likely the most valuable customers. The business question can be refined to ask: "Who are these high-point customers?"
    *   Similarly, `income` is right-skewed, which is a common and expected pattern for remuneration data in a general population. This suggests that marketing strategies should not treat all customers as having "average" income.

2.  **Patterns & Relationships:**
    *   The scatterplots demonstrate a **clear, positive, and moderately strong linear relationship** between both `income` (`remuneration`) and `spendingScore` with `loyaltyPoints`. The upward slope of the trend lines confirms that as income and spending propensity increase, so do the loyalty points. This directly answers the core business question by identifying two primary drivers of point accumulation.
    *   **Justification for Visualization:** Using `geom_smooth(method = "lm")` adds a layer of statistical insight directly onto the visualization, immediately confirming the linear nature of the trend without needing to run a separate correlation test at this stage. By coloring the points by `age`, we can visually inspect for a third variable's influence, concluding it is not a primary driver in this two-way relationship.

3.  **Groupings and Segmentation:**
    *   Visually, the distributions between male and female customers appear almost identical in both the faceted histogram and the violin plot. This suggests that, on its own, **gender is not a significant differentiating factor** for loyalty point accumulation.
    *   However, the interactive `datatable` summary, generated with `dplyr`, uncovers a more complex story. By grouping by both `gender` and `education`, we can precisely quantify which segments are most engaged. For example, we can see from the table that customers with a PhD have the highest mean loyalty points for both genders. This is an actionable insight, suggesting that marketing targeted at highly educated customers might be particularly effective for the loyalty program. This demonstrates how combining visual exploration with precise statistical summarization provides deeper insights than either method alone.

4. **Outliers and Spread:**
    *   The violin plot for `loyaltyPoints` by gender provides a more nuanced view than a standard boxplot. **Justification for Visualization:** While a boxplot shows the interquartile range (IQR), the violin plot's shape reveals the *density* of the data. We can see that the vast majority of both male and female customers are clustered below the 2000-point mark, with a long tail extending upwards. This visual confirmation of the skew is more impactful than a simple skewness statistic. The plot also confirms that while there are high-value outliers, they exist for both genders.

### R vs. Python for EDA: A Workflow Comparison
*   **Efficiency:** The R workflow proved to be more efficient for initial, broad-stroke EDA. Packages like `skimr` and `DataExplorer` provide comprehensive summaries and entire visualization reports with minimal code, significantly speeding up the initial understanding of the dataset.
*   **Visualization Power:** While Python's `seaborn` is excellent, `ggplot2` offers a more flexible and powerful grammar of graphics. The ease of adding layers, faceting, and customizing every aesthetic element allowed for the creation of more information-dense and publication-quality visuals.
*   **Reporting and Interactivity:** This is where R Markdown shines. The ability to seamlessly integrate code, output, narrative, and interactive elements (`plotly` widgets, `DT` tables) into a single, polished HTML document is a standout feature, making it an ideal tool for communicating results to both technical and non-technical audiences.

### 7. Future Work

To elevate this analysis to the highest standard and provide even more robust, actionable insights for Turtle Games, the following advanced techniques could be implemented.

1.  **Formal Statistical Hypothesis Testing:**
    *   **Objective:** To move from visual observation to statistical certainty.
    *   **Method:**
        *   Conduct an **independent samples t-test** to formally verify our observation that there is no statistically significant difference in the mean `loyaltyPoints` between male and female customers.
        *   Perform an **ANOVA (Analysis of Variance)** test to determine if the differences in mean `loyaltyPoints` across the five `education` levels are statistically significant. If they are, post-hoc tests (like Tukey's HSD) can identify exactly which groups differ.
    *   **Business Value:** This provides Turtle Games with statistical confidence to either disregard gender as a primary marketing segment or to focus marketing efforts on specific, high-performing educational segments.

2.  **Advanced Correlation Analysis with `corrplot`:**
    *   **Objective:** To create a more insightful and publication-quality correlation matrix.
    *   **Method:**
        *   Install and use the `corrplot` package to visualize the correlation matrix.
        *   Go beyond simple coefficients by overlaying the results of significance tests (p-values) on the plot, visually distinguishing between statistically significant and non-significant correlations.
    *   **Business Value:** This delivers a single, information-dense graphic that clearly communicates the strength and statistical validity of relationships between all numeric variables, providing a robust foundation for the predictive modeling in Assignment 6.

3.  **Investigating Non-Linear Relationships:**
    *   **Objective:** To test the assumption that all relationships are linear.
    *   **Method:**
        *   In our `ggplot2` scatterplots, replace `geom_smooth(method = "lm")` with `geom_smooth(method = "loess")`. The LOESS method fits a smooth local regression that can reveal curves and non-linear patterns.
    *   **Business Value:** If a non-linear pattern is discovered (e.g., the relationship between `age` and `loyaltyPoints` increases up to a certain point and then plateaus), it would be a critical insight, suggesting that a simple linear regression model might not be the most accurate choice and that more advanced models (e.g., polynomial regression or GAMs) should be considered. This demonstrates a sophisticated approach to model validation.

4.  **From Report to Interactive Data Product with `flexdashboard`:**
    *   **Objective:** To convert the static R Markdown report into a simple, interactive dashboard for business stakeholders.
    *   **Method:**
        *   Restructure the R Markdown file using the `flexdashboard` format.
        *   Incorporate input controls (e.g., a slider for `spendingScore`) using `shiny` components, allowing users to filter the data and see the visualizations update in real-time.
    *   **Business Value:** This represents the pinnacle of communicating data insights. Instead of a report, you deliver a tool. Stakeholders at Turtle Games could use this dashboard to explore customer segments on their own, answer their own questions, and build a deeper, more intuitive understanding of the data, thereby greatly increasing the impact and adoption of the analysis.
---

# Assignment 6: Predictive Modeling

Building on the EDA, we will now perform statistical analysis and create a multiple linear regression (MLR) model to predict `loyalty_points`.

## 1. Statistical Analysis

Let's look at the correlation between our numeric variables to select features for our model. A correlation matrix is a great tool for this.

```{r correlation_matrix}
# Select only numeric columns for correlation analysis
numeric_vars <- reviews %>% select_where(is.numeric)

# Calculate the correlation matrix
cor_matrix <- cor(numeric_vars, use = "complete.obs")

# Print the correlation matrix (rounded for readability)
round(cor_matrix, 2)

# For a better visual, you can use the corrplot package
# renv::install("corrplot")
# library(corrplot)
# corrplot(cor_matrix, method = "circle")
```

**Justification for Feature Selection:**
* Based on the correlation matrix, `remuneration` and `spending_score` show the strongest linear relationships with `loyalty_points`.
* Age also has a moderate correlation.
* We will use these three variables as predictors in our initial model.
* **Potential Concerns:** *Mention multicollinearity if predictors are highly correlated with each other. Check VIF values if needed.*

## 2. Building the Multiple Linear Regression (MLR) Model

We'll create a model with the formula:
`loyalty_points ~ remuneration + spending_score + age`

```{r build_mlr_model}
# Build the linear regression model
mlr_model <- lm(loyalty_points ~ remuneration + spending_score + age, data = reviews)

# Get the model summary
summary(mlr_model)
```

## 3. Model Evaluation and Interpretation

The model summary provides crucial statistics to evaluate its performance.

* **Coefficients (Estimate):** *Interpret the coefficients. For every one-unit increase in `remuneration`, `loyalty_points` increases by [value], holding other variables constant.*
* **P-values (Pr(>|t|)):** *All predictors have very small p-values (< 0.05), indicating they are statistically significant.*
* **R-squared:** *The Adjusted R-squared value is [value]. This means our model explains approximately [value * 100]% of the variance in `loyalty_points`. Comment on whether this is a good fit.*
* **F-statistic:** *The F-statistic is large and its p-value is very small, which suggests that the model is useful and better than a model with no predictors.*

### Visualizing Model Fit

We can plot the actual vs. predicted values to visually assess the model's performance.

```{r visualize_model}
# Get predicted values
predicted_points <- predict(mlr_model, newdata = reviews)

# Create a data frame for plotting
plot_data <- data.frame(
  Actual = reviews$loyalty_points,
  Predicted = predicted_points
)

# Plot actual vs. predicted values
ggplot(plot_data, aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red", size = 1) +
  labs(title = "Actual vs. Predicted Loyalty Points",
       x = "Actual Loyalty Points",
       y = "Predicted Loyalty Points") +
  theme_minimal()
```

## 4. Using the Model for Prediction

Let's demonstrate how to use the model to predict loyalty points for a new, hypothetical customer.

```{r predict_scenarios}
# Create a new data frame for prediction scenarios
new_customers <- data.frame(
  remuneration = c(50, 90, 120),
  spending_score = c(40, 85, 20),
  age = c(30, 45, 60)
)

# Use the model to predict loyalty points
predicted_loyalty <- predict(mlr_model, newdata = new_customers)

# Display the predictions
new_customers$predicted_loyalty_points <- round(predicted_loyalty, 0)
print(new_customers)
```

# Conclusion and Recommendations

## Summary of Findings
* *Briefly summarize the key insights from both the EDA and the MLR model.*
* *Example: Customer spending score and remuneration are significant positive predictors of loyalty points. The developed model can explain X% of the variance in loyalty points.*

## Recommendations for the Business
* **Marketing Efforts:** *Where should the business focus its marketing? Suggest targeting customers with high spending scores or high remuneration, as they tend to accumulate more points.*
* **Loyalty Program Improvements:** *How could the program be improved? Perhaps offer tiered rewards based on spending scores to encourage more engagement.*
* **Analysis Improvements:** *What are the next steps? Consider non-linear models if the relationships aren't strictly linear. Also, collecting more feature data (e.g., frequency of purchase, product categories) could significantly improve model accuracy.*